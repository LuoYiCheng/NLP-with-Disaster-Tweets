Kaggle: https://www.kaggle.com/competitions/nlp-getting-started/leaderboard

I spent my free time last weekend practicing NLP by participating in a classic Kaggle competition, "Natural Language Processing with Disaster Tweets." One of my motivations was that I took a machine learning course in the electrical and computer engineering department last semester and was introduced to the knowledge of transformers. I wanted to implement a task as practice, so I chose a relatively simple sentiment analysis task. I also tried Word Embedding, GRU in this task.



However, I was pleasantly surprised to learn some techniques for text preprocessing, which I implemented and greatly improved my leaderboard score. As of now, my ranking on the leaderboard is 67 out of 1052. I have recorded the detailed processing steps and takeaways in 'Tweets.ipynb', and I have already pushed my project to Github. Friends who are interested in the content are welcome to visit my github to see it, and I also welcome any feedback and advice from experts. Thank you!
